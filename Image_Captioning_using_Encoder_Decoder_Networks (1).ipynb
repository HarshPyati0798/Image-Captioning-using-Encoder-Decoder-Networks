{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Captioning using Encoder Decoder Networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "2dJNmwYIxkE4",
        "7zurenMyxkGj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "FnsR2qscwW1b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Generating Captions for images using RNNs and CNNs**\n",
        "### Data Set: Flickr8k - 8091 Training Samples\n",
        "### Predictions:  Recursive Generation, Using the start symbol, the next word is predicted. In the next pass, uses both the start symbol and the word earlier predicted to predict the next word in the sentence until the end sequence is obtained.\n",
        "### Model - VCG model for extracting the image features, then passed through subsequent Dense, Dropout and 2 layers of  LSTM. \n",
        "### Trained for 15 epochs. Can be trained furthermore, to obtain better results. \n",
        "### Uses categorical cross entropy as the loss function\n",
        "### To see the results, change the directory in the code, and then upload the image, you want to generate the captions for(Note that the program won't work properly if the image comes from a different distribution). And call extract feature and generate_desc functions with the necessary params, as specified in the function call.\n"
      ]
    },
    {
      "metadata": {
        "id": "EvbaHEX9xkDV",
        "colab_type": "code",
        "outputId": "1a87920c-8eb6-4ef8-e0ef-3102d8f3fbd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical,plot_model\n",
        "from keras.layers import Dense,Dropout,LSTM,GRU,Input,add,Embedding"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "e7hz7tTBxkDc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AD0cshFxykji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = 'drive/Image Captioner/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oPJdfVBVxkDw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import load_img,img_to_array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6FALEeruvxgv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## No need to run these statements. Result is in a pickle file already"
      ]
    },
    {
      "metadata": {
        "id": "sRaFke7sxkD1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load the Images"
      ]
    },
    {
      "metadata": {
        "id": "6YssoO4nxkD3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_images(directory):\n",
        "    images = dict()\n",
        "    for img in os.listdir(directory):\n",
        "        filename = directory + img\n",
        "        image = load_img(filename,target_size=(224,224))\n",
        "        image = img_to_array(image)\n",
        "        image = image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n",
        "        name = img.split('.')[0]\n",
        "        images[name] = image\n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ODTb6wC6xkD6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "directory = data_dir + 'Flicker8k_Dataset/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w9rR-lkSxkD9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "image_data = load_images(directory=directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yEgLbrwNxkEB",
        "colab_type": "code",
        "outputId": "c0022b39-faa8-40cb-c0a8-0800fba39f21",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "type(image_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "16EPSp5BxkEI",
        "colab_type": "code",
        "outputId": "f48d175f-773a-4b69-ec23-80b7674cc007",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('the length of the image file is {}'.format(len(image_data)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the length of the image file is 8091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zbd1LXZ2xkEO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Defining the VGG Model for obtaining features from Images"
      ]
    },
    {
      "metadata": {
        "id": "33QTh65MxkEP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model,load_model\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.applications import VGG16\n",
        "from pickle import dump,load"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a-rMvQ7lxkET",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = VGG16()\n",
        "model.layers.pop() # Removes the last activation layer\n",
        "model = Model(inputs = model.inputs,outputs = model.layers[-1].output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "EgJuvswexkEW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = dict()\n",
        "for key,image in image_data.items():\n",
        "    feature = model.predict(image,verbose = 1)\n",
        "    features[key] = feature\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xQUR7WpTxkEa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pickle import dump\n",
        "dump(features, open('features.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5DOh8rssv_JF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Begin From Here"
      ]
    },
    {
      "metadata": {
        "id": "KqyOoo5IxkEf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the Text Data"
      ]
    },
    {
      "metadata": {
        "id": "SQlxqw1kxkEh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = data_dir + 'Flickr8k_text/Flickr8k.token.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwwIEYl2xkEl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file = open(data,'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "szdVYT9pxkEq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "doc = file.read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2dJNmwYIxkE4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The document consists of the image id followed by the no.of the image followed by the text description. There are 5 descriptions per image id"
      ]
    },
    {
      "metadata": {
        "id": "xXk5Gf3ExkE5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Dictionary to hold the image id as the key and the list of descriptions as its values"
      ]
    },
    {
      "metadata": {
        "id": "HbB7PUoyxkE7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "descriptions = dict()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6CMo3uYExkFA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for line in doc.split('\\n'):\n",
        "    # split line by white space\n",
        "    tokens = line.split()\n",
        "    #print(tokens)\n",
        "    #Extract the image id, to use it as key for the dictionary. Image Desc will be joined together to create a list\n",
        "    image_id, image_desc = tokens[0], tokens[1:]\n",
        "    #print(image_id)\n",
        "    #print(image_desc)\n",
        "    # extract filename from image id\n",
        "    image_id = image_id.split('.')[0]\n",
        "\n",
        "    # convert description tokens back to string\n",
        "    image_desc = ' '.join(image_desc)\n",
        "    if image_id not in descriptions:\n",
        "        descriptions[image_id] = list()\n",
        "    descriptions[image_id].append(image_desc)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "STiNomMmxkFF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(descriptions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Ytdar0uxkFN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "descriptions['101654506_8eb26cfb60']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c3QDfIlyxkFT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### We have 5 lines of description for each image file. We need to clean the descriptions now"
      ]
    },
    {
      "metadata": {
        "id": "218qiRVLxkFU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import string\n",
        "## We need to remove the punctuation marks first\n",
        "table = str.maketrans('','',string.punctuation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E3sUUBiPxkFY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for key,desc_list in descriptions.items():\n",
        "    for i in range(len(desc_list)):\n",
        "        desc = desc_list[i]\n",
        "        # Tokenize each single word in the list\n",
        "        desc = desc.split()\n",
        "        # Convert each word to its lower case format\n",
        "        desc = [word.lower() for word in desc]\n",
        "        # Remove punctuation from each word in the list\n",
        "        desc = [word.translate(table) for word in desc]\n",
        "        # Remove the tokens which have length = 1\n",
        "        desc = [word for word in desc if len(word) > 1]\n",
        "        # Remove tokens with numbers inside them\n",
        "        desc = [word for word in desc if word.isalpha()]\n",
        "        # Store it as a string\n",
        "        desc_list[i] = ' '.join(desc)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cLuRUVtNxkFc",
        "colab_type": "code",
        "outputId": "17704d12-4cf7-480e-9338-c4133ee76526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "descriptions['101654506_8eb26cfb60']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['brown and white dog is running through the snow',\n",
              " 'dog is running in the snow',\n",
              " 'dog running through snow',\n",
              " 'white and brown dog is running through snow covered field',\n",
              " 'the white and brown dog is running over the surface of the snow']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "WXFTaGZfxkFg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Creating a vocabulary of all the unique words present in the descriptions"
      ]
    },
    {
      "metadata": {
        "id": "hGxtAahqxkFi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab = set()\n",
        "for key in descriptions.keys():\n",
        "    [vocab.update(d.split()) for d in descriptions[key]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FndyHcxcxkFl",
        "colab_type": "code",
        "outputId": "41947261-3eb9-428f-c77a-30977c7e1851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8763"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "kgHcD-9exkFr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# There are around 8763 unique words in our vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zlgct6HgxkFt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_desc(descriptions,filename):\n",
        "    lines = list()\n",
        "    for key,desc_list in descriptions.items():\n",
        "        for desc in desc_list:\n",
        "            lines.append(key + '-' + desc)\n",
        "    data = '\\n'.join(lines)\n",
        "    file = open(filename,'w')\n",
        "    file.write(data)\n",
        "    file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wFIsg-0zxkFv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_desc(descriptions,'descriptions.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "natzlGElxkFx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ]
    },
    {
      "metadata": {
        "id": "_PNzzb70xkFy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_doc(filename):\n",
        "    file = open(filename,'r')\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fVJ61mDfxkF0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_set(filename):\n",
        "    doc = load_doc(filename)\n",
        "    last = doc[-1]\n",
        "    dataset = list()\n",
        "    # Process the data line by line\n",
        "    for line in doc.split('\\n'):\n",
        "        if len(line) >= 1: # If it is not the last line\n",
        "            identifier = line.split('.')[0]\n",
        "            dataset.append(identifier)\n",
        "    return set(dataset)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mWFIj_VsxkF4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_cleaned_desc(filename,dataset):\n",
        "    doc = load_doc(filename)\n",
        "    descriptions = dict()\n",
        "    for line in doc.split('\\n'):\n",
        "        tokens = line.split('-')\n",
        "        image_id,image_desc = tokens[0],tokens[1:]\n",
        "        \n",
        "        if image_id in dataset:\n",
        "            if image_id not in descriptions:\n",
        "                descriptions[image_id] = list()\n",
        "            desc = 'start ' + ' '.join(image_desc) + ' end'\n",
        "            descriptions[image_id].append(desc)\n",
        "    return descriptions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oULuyFOsxkF6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pickle import load\n",
        "def load_image_features(filename,dataset):\n",
        "    all_features = load(open(filename,'rb'))\n",
        "    features = {k:all_features[k] for k in dataset}\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qcKG1a8rxkF-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = data_dir + 'Flickr8k_text/Flickr_8k.trainImages.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u1_TNGaPxkGA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = load_set(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rtHGb49lxkGF",
        "colab_type": "code",
        "outputId": "f5169355-4156-4be4-cdf3-80cb4d98bccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('The length of the dataset is {}'.format(len(train)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The length of the dataset is 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oDYePLJfxkGM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Load the descriptions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lA_mdTx3xkGP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "desc = load_cleaned_desc('descriptions.txt',train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "biIsKSiCxkGR",
        "colab_type": "code",
        "outputId": "dbcfa1c2-aa95-4746-b31c-4288fa40f915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Descriptions Length - {}'.format(len(desc)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Descriptions Length - 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hYg9JIuKxkGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "images = load_image_features(data_dir + 'features.pkl',train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TSonT-77xkGY",
        "colab_type": "code",
        "outputId": "b0cc7339-71aa-4ba2-b3b6-4c938809238b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print('Images length - {}'.format(len(images)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images length - 6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "__61PBWLxkGc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "id = '1022454332_6af2c1449a'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "15NbQWAixkGg",
        "colab_type": "code",
        "outputId": "4820ba70-720d-4708-d2ae-65a4b4ae5532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "type(desc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "7zurenMyxkGj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### So, now we have a training data of 6000 images and captions"
      ]
    },
    {
      "metadata": {
        "id": "KTtQMZT1xkGj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare the Data for the embedding layer"
      ]
    },
    {
      "metadata": {
        "id": "CBXhP7ANxkGk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### First, we need to convert words into integer tokens. Then, from the tokens, we have to create the sequences that would be fed into the model"
      ]
    },
    {
      "metadata": {
        "id": "n8dvHtcxxkGl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a list of all captions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1hA4IoARxkGr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_lines(descriptions):\n",
        "    all_desc = list()\n",
        "    for key in descriptions.keys():\n",
        "        [all_desc.append(d) for d in descriptions[key]]\n",
        "    return all_desc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VLRqvm5yxkGw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Fit a tokenizer to this list\n",
        "def create_tokenizer(descriptions):\n",
        "    lines = to_lines(descriptions)\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m5lm210RxkG2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = create_tokenizer(desc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jRZhFUZ_xkG7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d54R-QlOxkG-",
        "colab_type": "code",
        "outputId": "ea10eda4-90f5-45d1-cd07-1b23aa865a65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7577"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "ladQS2E2xkHD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Next, we have to create sequences of fixed length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NSdfCfKJxkHF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create sequences of images, input sequences and output words for an image\n",
        "def create_sequences(tokenizer, max_length, desc_list, photo):\n",
        "\tX1, X2, y = list(), list(), list()\n",
        "\t# walk through each description for the image\n",
        "\tfor desc in desc_list:\n",
        "\t\t# encode the sequence\n",
        "\t\tseq = tokenizer.texts_to_sequences([desc])[0]\n",
        "\t\t# split one sequence into multiple X,y pairs\n",
        "\t\tfor i in range(1, len(seq)):\n",
        "\t\t\t# split into input and output pair\n",
        "\t\t\tin_seq, out_seq = seq[:i], seq[i]\n",
        "\t\t\t# pad input sequence\n",
        "\t\t\tin_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "\t\t\t# encode output sequence\n",
        "\t\t\tout_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "\t\t\t# store\n",
        "\t\t\tX1.append(photo)\n",
        "\t\t\tX2.append(in_seq)\n",
        "\t\t\ty.append(out_seq)\n",
        "\treturn np.array(X1), np.array(X2), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-HEjHwoKxkHI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Generator fn to progressively create sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KUeWAckbxkHN",
        "colab_type": "code",
        "outputId": "4cd72b44-3565-4abc-8387-72bd4da9baf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(descriptions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8092"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "csbALJkIxkHR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_generator(descriptions, photos, tokenizer, max_length):\n",
        "    # loop for ever over images\n",
        "    while True:\n",
        "        for key, desc_list in descriptions.items():\n",
        "            # retrieve the photo feature\n",
        "            photo = photos[key][0]\n",
        "            in_img, in_seq, out_word = create_sequences(tokenizer, max_length, desc_list, photo)\n",
        "            yield [[in_img, in_seq], out_word] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SFrCNWjexkHT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Define the max length to be passed onto the create_sequences function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-VouT-cxkHX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculate the length of the description with the most words\n",
        "def max_length(descriptions):\n",
        "    lines = to_lines(descriptions)\n",
        "    return max(len(d.split()) for d in lines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hrf1M7BNxkHZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_length = max_length(descriptions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nF1xXPe4xkHb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define the model"
      ]
    },
    {
      "metadata": {
        "id": "Xsqx7H9QxkHd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def def_model(vocab_size,max_length):\n",
        "    # Extract features from the VGG Model\n",
        "    inputs1 = Input(shape = (4096,))\n",
        "    fe1 = Dropout(0.5)(inputs1)\n",
        "    fe2 = Dense(256,activation = 'relu')(fe1)\n",
        "   \n",
        "    \n",
        "    # Sequence Model\n",
        "    inputs2 = Input(shape = (max_length,))\n",
        "    seq1 = Embedding(vocab_size,256,mask_zero = True)(inputs2)\n",
        "    seq2 = Dropout(0.5)(seq1)\n",
        "    seq3 = LSTM(256,return_sequences=True)(seq2)\n",
        "    seq4 = Dropout(0.5)(seq3)\n",
        "    seq5 = LSTM(256)(seq4)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Decoder model: Take the inputs from the images, and the sequences\n",
        "    decoder1 = add([fe2,seq5])\n",
        "    decoder2 = Dense(256,activation = 'relu')(decoder1)\n",
        "    outputs = Dense(vocab_size,activation = 'softmax')(decoder2)\n",
        "    \n",
        "    # Combined Model\n",
        "    m = Model(inputs = [inputs1,inputs2],outputs = outputs)\n",
        "    m.compile(loss = 'categorical_crossentropy',optimizer = 'adam')\n",
        "    \n",
        "    # Plot the model\n",
        "    #plot_model(model,to_file = 'model.png',show_shapes = True)\n",
        "    return m\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "utRLuamFxkHf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Define the checkpoint callback"
      ]
    },
    {
      "metadata": {
        "id": "FId46iZXxkHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rDFyLDaIsS53",
        "colab_type": "code",
        "outputId": "b351c983-922b-41a1-dd4d-df7a3bdf094f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "steps = len(desc)\n",
        "model = def_model(vocab_size,max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sENrLjYgxkHi",
        "colab_type": "code",
        "outputId": "093d01af-68fe-46ed-976d-729801141f6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(epochs):\n",
        "  print('Epoch number ',i+1)\n",
        "  generator = data_generator(desc,images,tokenizer,max_length)\n",
        "  model.fit_generator(generator,epochs = 1,steps_per_epoch = steps,verbose = 1)\n",
        "  model.save(data_dir + 'model_' + str(i) + '.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number  1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1132s 189ms/step - loss: 4.7783\n",
            "Epoch number  2\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1138s 190ms/step - loss: 4.0573\n",
            "Epoch number  3\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1143s 190ms/step - loss: 3.8343\n",
            "Epoch number  4\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1166s 194ms/step - loss: 3.6985\n",
            "Epoch number  5\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1157s 193ms/step - loss: 3.6106\n",
            "Epoch number  6\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1150s 192ms/step - loss: 3.5481\n",
            "Epoch number  7\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1150s 192ms/step - loss: 3.5059\n",
            "Epoch number  8\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1149s 191ms/step - loss: 3.4732\n",
            "Epoch number  9\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1163s 194ms/step - loss: 3.4481\n",
            "Epoch number  10\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1154s 192ms/step - loss: 3.4217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kEr6gZx5Vqei",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Evaluate the Model**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "z-__hBQfVo6h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Function to map an integer to a word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "20UqdF6jV1d0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def word_for_id(num, tokenizer):\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == num:\n",
        "\t\t\treturn word\n",
        "\treturn None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ARufN0b3ExKD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training it for 5 more epochs"
      ]
    },
    {
      "metadata": {
        "id": "g0pse6_NWELd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "m = load_model(data_dir + 'model_9.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ilNEOEvCE5Rz",
        "colab_type": "code",
        "outputId": "cc95c3a7-6c14-4942-b516-ab94e0bade8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print('Epoch number ',i+11)\n",
        "  generator = data_generator(desc,images,tokenizer,max_length)\n",
        "  m.fit_generator(generator,epochs = 1,steps_per_epoch = steps,verbose = 1)\n",
        "  m.save(data_dir + 'model_' + str(i + 10) + '.h5')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number  11\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1164s 194ms/step - loss: 3.4106\n",
            "Epoch number  12\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1144s 191ms/step - loss: 3.3959\n",
            "Epoch number  13\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1143s 190ms/step - loss: 3.3875\n",
            "Epoch number  14\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1127s 188ms/step - loss: 3.3812\n",
            "Epoch number  15\n",
            "Epoch 1/1\n",
            "6000/6000 [==============================] - 1144s 191ms/step - loss: 3.3687\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lz9q60BnWIy3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Function to recursively generate descriptions for a given image**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "YzG4GX08WShW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_desc(model, tokenizer, photo, max_length):\n",
        "\t# seed the generation process\n",
        "\tin_text = 'start'\n",
        "\t# iterate over the whole length of the sequence\n",
        "\tfor i in range(max_length):\n",
        "\t\t# integer encode input sequence\n",
        "\t\tsequence = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# pad input\n",
        "\t\tsequence = pad_sequences([sequence], maxlen=max_length)\n",
        "\t\t# predict next word\n",
        "\t\tyhat = model.predict([photo,sequence], verbose=0)\n",
        "\t\t# convert probability to integer\n",
        "\t\tyhat = np.argmax(yhat)\n",
        "\t\t# map integer to word\n",
        "\t\tword = word_for_id(yhat, tokenizer)\n",
        "\t\t# stop if we cannot map the word\n",
        "\t\tif word is None:\n",
        "\t\t\tbreak\n",
        "\t\t# append as input for generating the next word\n",
        "\t\tin_text += ' ' + word\n",
        "\t\t# stop if we predict the end of the sequence\n",
        "\t\tif word == 'end':\n",
        "\t\t\tbreak\n",
        "\treturn in_text\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9XLxVjPoX0bP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GOGsg0TEYGxq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Model using Bleu Score"
      ]
    },
    {
      "metadata": {
        "id": "AVZi5QTJYK-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "def evaluate_model(model, descriptions, photos, tokenizer, max_length):\n",
        "\tactual, predicted = list(), list()\n",
        "\t# step over the whole set\n",
        "\tfor key, desc_list in descriptions.items():\n",
        "\t\t# generate description\n",
        "\t\tyhat = generate_desc(model, tokenizer, photos[key], max_length)\n",
        "\t\t# store actual and predicted\n",
        "\t\treferences = [d.split() for d in desc_list]\n",
        "\t\tactual.append(references)\n",
        "\t\tpredicted.append(yhat.split())\n",
        "\t# calculate BLEU score\n",
        "\tprint('BLEU-1: %f' % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))\n",
        "\tprint('BLEU-2: %f' % corpus_bleu(actual, predicted, weights=(0.5, 0.5, 0, 0)))\n",
        "\tprint('BLEU-3: %f' % corpus_bleu(actual, predicted, weights=(0.3, 0.3, 0.3, 0)))\n",
        "\tprint('BLEU-4: %f' % corpus_bleu(actual, predicted, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-UMGzE0UZZtR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = data_dir + 'Flickr8k_text/Flickr_8k.testImages.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v9Z3eNFuZzpz",
        "colab_type": "code",
        "outputId": "ba16e038-5dfe-4d7d-cb7e-d118444c867b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "test_data = load_set(filename)\n",
        "print('Length of the dataset is {}'.format(len(test_data)))\n",
        "\n",
        "test_desc = load_cleaned_desc('descriptions.txt',test_data)\n",
        "print('Length of the descriptions is {}'.format(len(test_desc)))\n",
        "\n",
        "test_features = load_image_features(data_dir + 'features.pkl',test_data)\n",
        "print('Length of the images is {}'.format(len(test_features)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of the dataset is 1000\n",
            "Length of the descriptions is 1000\n",
            "Length of the images is 1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Focc14NKafeC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TU0WlH_GaqLp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Load the model"
      ]
    },
    {
      "metadata": {
        "id": "Lh1-JLJcatHI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "filename = data_dir + 'model_14.h5'\n",
        "model = load_model(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XNtL8xzda08u",
        "colab_type": "code",
        "outputId": "893eed0f-6596-44bc-bc89-935c9ae4c313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "evaluate_model(model,test_desc,test_features,tokenizer,max_length)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.537706\n",
            "BLEU-2: 0.278727\n",
            "BLEU-3: 0.176075\n",
            "BLEU-4: 0.072834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nYEENcE2b0DV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate New captions"
      ]
    },
    {
      "metadata": {
        "id": "yS7sPktybDPY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "def extract_feature(filename):\n",
        "  model = VGG16()\n",
        "  model.layers.pop()\n",
        "  model = Model(inputs = model.inputs,outputs = model.layers[-1].output)\n",
        "  img = load_img(filename,target_size=(224,224))\n",
        "  img = img_to_array(img)\n",
        "  img = img.reshape((1,img.shape[0],img.shape[1],img.shape[2]))\n",
        "  img = preprocess_input(img)\n",
        "  feature = model.predict(img)\n",
        "  return [img,feature]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SanH9feDg5bq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = create_tokenizer(desc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rio0f7yphKaU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dump(tokenizer,open('tokenizer.pkl','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kp8UnXnOhQTZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = load(open('tokenizer.pkl','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pYcDO5EkEZQP",
        "colab_type": "code",
        "outputId": "6fd9257f-5c5b-4a0f-a82c-abbd99364fb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "img,photo_dog = extract_feature(data_dir + 'sample.jpg')\n",
        "print(generate_desc(model,tokenizer,photo_dog,max_length))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start dog is running through the grass end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f2wm3rNdwOsm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Alternative Model - Yet to train. Uses GRU instead of LSTM "
      ]
    },
    {
      "metadata": {
        "id": "gqGy2_eNKPdx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def def_model(vocab_size,max_length):\n",
        "    # Extract features from the VGG Model\n",
        "    inputs1 = Input(shape = (4096,))\n",
        "    fe1 = Dropout(0.5)(inputs1)\n",
        "    fe2 = Dense(256,activation = 'relu')(fe1)\n",
        "   \n",
        "    \n",
        "    # Sequence Model\n",
        "    inputs2 = Input(shape = (max_length,))\n",
        "    seq1 = Embedding(vocab_size,256,mask_zero = True)(inputs2)\n",
        "    seq2 = Dropout(0.5)(seq1)\n",
        "    seq3 = GRU(256,return_sequences=True)(seq2)\n",
        "    seq4 = Dropout(0.5)(seq3)\n",
        "    seq5 = GRU(256)(seq4)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Decoder model: Take the inputs from the images, and the sequences\n",
        "    decoder1 = add([fe2,seq5])\n",
        "    decoder2 = Dense(256,activation = 'relu')(decoder1)\n",
        "    outputs = Dense(vocab_size,activation = 'softmax')(decoder2)\n",
        "    \n",
        "    # Combined Model\n",
        "    m = Model(inputs = [inputs1,inputs2],outputs = outputs)\n",
        "    m.compile(loss = 'categorical_crossentropy',optimizer = 'adam')\n",
        "    \n",
        "    # Plot the model\n",
        "    #plot_model(model,to_file = 'model.png',show_shapes = True)\n",
        "    return m"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
